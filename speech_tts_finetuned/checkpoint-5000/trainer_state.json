{
  "best_global_step": 500,
  "best_metric": 55.797,
  "best_model_checkpoint": "speech_tts_finetuned/checkpoint-500",
  "epoch": 2.196836555360281,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.021968365553602813,
      "grad_norm": 43.18168258666992,
      "learning_rate": 9.800000000000001e-07,
      "loss": 1.9781,
      "step": 50
    },
    {
      "epoch": 0.043936731107205626,
      "grad_norm": 10.548097610473633,
      "learning_rate": 1.98e-06,
      "loss": 0.9736,
      "step": 100
    },
    {
      "epoch": 0.06590509666080843,
      "grad_norm": 17.612117767333984,
      "learning_rate": 2.9800000000000003e-06,
      "loss": 0.6694,
      "step": 150
    },
    {
      "epoch": 0.08787346221441125,
      "grad_norm": 8.590121269226074,
      "learning_rate": 3.980000000000001e-06,
      "loss": 0.5789,
      "step": 200
    },
    {
      "epoch": 0.10984182776801406,
      "grad_norm": 9.155637741088867,
      "learning_rate": 4.980000000000001e-06,
      "loss": 0.5758,
      "step": 250
    },
    {
      "epoch": 0.13181019332161686,
      "grad_norm": 5.197819232940674,
      "learning_rate": 5.98e-06,
      "loss": 0.5471,
      "step": 300
    },
    {
      "epoch": 0.15377855887521968,
      "grad_norm": 3.9159135818481445,
      "learning_rate": 6.98e-06,
      "loss": 0.5312,
      "step": 350
    },
    {
      "epoch": 0.1757469244288225,
      "grad_norm": 4.727983474731445,
      "learning_rate": 7.980000000000002e-06,
      "loss": 0.5344,
      "step": 400
    },
    {
      "epoch": 0.1977152899824253,
      "grad_norm": 4.769108772277832,
      "learning_rate": 8.98e-06,
      "loss": 0.4928,
      "step": 450
    },
    {
      "epoch": 0.21968365553602812,
      "grad_norm": 4.321680068969727,
      "learning_rate": 9.980000000000001e-06,
      "loss": 0.5,
      "step": 500
    },
    {
      "epoch": 0.21968365553602812,
      "eval_runtime": 39.6255,
      "eval_samples_per_second": 55.797,
      "eval_steps_per_second": 6.99,
      "step": 500
    },
    {
      "epoch": 0.24165202108963094,
      "grad_norm": 4.6209893226623535,
      "learning_rate": 9.891111111111113e-06,
      "loss": 0.4878,
      "step": 550
    },
    {
      "epoch": 0.26362038664323373,
      "grad_norm": 4.256308555603027,
      "learning_rate": 9.780000000000001e-06,
      "loss": 0.4975,
      "step": 600
    },
    {
      "epoch": 0.28558875219683655,
      "grad_norm": 3.223604917526245,
      "learning_rate": 9.66888888888889e-06,
      "loss": 0.4817,
      "step": 650
    },
    {
      "epoch": 0.30755711775043937,
      "grad_norm": 8.869821548461914,
      "learning_rate": 9.557777777777777e-06,
      "loss": 0.4698,
      "step": 700
    },
    {
      "epoch": 0.3295254833040422,
      "grad_norm": 5.316766262054443,
      "learning_rate": 9.446666666666667e-06,
      "loss": 0.4621,
      "step": 750
    },
    {
      "epoch": 0.351493848857645,
      "grad_norm": 2.1295058727264404,
      "learning_rate": 9.335555555555557e-06,
      "loss": 0.4591,
      "step": 800
    },
    {
      "epoch": 0.37346221441124783,
      "grad_norm": 5.189889430999756,
      "learning_rate": 9.224444444444445e-06,
      "loss": 0.4747,
      "step": 850
    },
    {
      "epoch": 0.3954305799648506,
      "grad_norm": 3.733510732650757,
      "learning_rate": 9.113333333333335e-06,
      "loss": 0.4529,
      "step": 900
    },
    {
      "epoch": 0.4173989455184534,
      "grad_norm": 5.196063041687012,
      "learning_rate": 9.002222222222223e-06,
      "loss": 0.4521,
      "step": 950
    },
    {
      "epoch": 0.43936731107205623,
      "grad_norm": 9.349751472473145,
      "learning_rate": 8.891111111111111e-06,
      "loss": 0.4711,
      "step": 1000
    },
    {
      "epoch": 0.43936731107205623,
      "eval_runtime": 43.9488,
      "eval_samples_per_second": 50.308,
      "eval_steps_per_second": 6.303,
      "step": 1000
    },
    {
      "epoch": 0.46133567662565905,
      "grad_norm": 3.5636720657348633,
      "learning_rate": 8.78e-06,
      "loss": 0.4662,
      "step": 1050
    },
    {
      "epoch": 0.4833040421792619,
      "grad_norm": 3.359553098678589,
      "learning_rate": 8.66888888888889e-06,
      "loss": 0.4555,
      "step": 1100
    },
    {
      "epoch": 0.5052724077328646,
      "grad_norm": 8.546004295349121,
      "learning_rate": 8.557777777777778e-06,
      "loss": 0.4538,
      "step": 1150
    },
    {
      "epoch": 0.5272407732864675,
      "grad_norm": 7.603754043579102,
      "learning_rate": 8.446666666666668e-06,
      "loss": 0.4513,
      "step": 1200
    },
    {
      "epoch": 0.5492091388400703,
      "grad_norm": 3.815112352371216,
      "learning_rate": 8.335555555555556e-06,
      "loss": 0.4396,
      "step": 1250
    },
    {
      "epoch": 0.5711775043936731,
      "grad_norm": 5.0320940017700195,
      "learning_rate": 8.224444444444444e-06,
      "loss": 0.4575,
      "step": 1300
    },
    {
      "epoch": 0.5931458699472759,
      "grad_norm": 3.307823657989502,
      "learning_rate": 8.113333333333334e-06,
      "loss": 0.4518,
      "step": 1350
    },
    {
      "epoch": 0.6151142355008787,
      "grad_norm": 4.939947128295898,
      "learning_rate": 8.002222222222222e-06,
      "loss": 0.4478,
      "step": 1400
    },
    {
      "epoch": 0.6370826010544816,
      "grad_norm": 3.6390373706817627,
      "learning_rate": 7.891111111111112e-06,
      "loss": 0.4426,
      "step": 1450
    },
    {
      "epoch": 0.6590509666080844,
      "grad_norm": 4.834080696105957,
      "learning_rate": 7.78e-06,
      "loss": 0.4366,
      "step": 1500
    },
    {
      "epoch": 0.6590509666080844,
      "eval_runtime": 44.1872,
      "eval_samples_per_second": 50.037,
      "eval_steps_per_second": 6.269,
      "step": 1500
    },
    {
      "epoch": 0.6810193321616872,
      "grad_norm": 8.030613899230957,
      "learning_rate": 7.66888888888889e-06,
      "loss": 0.4439,
      "step": 1550
    },
    {
      "epoch": 0.70298769771529,
      "grad_norm": 4.16226053237915,
      "learning_rate": 7.557777777777779e-06,
      "loss": 0.4499,
      "step": 1600
    },
    {
      "epoch": 0.7249560632688928,
      "grad_norm": 2.88299560546875,
      "learning_rate": 7.446666666666668e-06,
      "loss": 0.4369,
      "step": 1650
    },
    {
      "epoch": 0.7469244288224957,
      "grad_norm": 14.14426326751709,
      "learning_rate": 7.335555555555556e-06,
      "loss": 0.4405,
      "step": 1700
    },
    {
      "epoch": 0.7688927943760984,
      "grad_norm": 3.7599637508392334,
      "learning_rate": 7.224444444444445e-06,
      "loss": 0.4426,
      "step": 1750
    },
    {
      "epoch": 0.7908611599297012,
      "grad_norm": 6.873780250549316,
      "learning_rate": 7.113333333333334e-06,
      "loss": 0.4336,
      "step": 1800
    },
    {
      "epoch": 0.812829525483304,
      "grad_norm": 2.6701292991638184,
      "learning_rate": 7.0022222222222225e-06,
      "loss": 0.4422,
      "step": 1850
    },
    {
      "epoch": 0.8347978910369068,
      "grad_norm": 2.561863422393799,
      "learning_rate": 6.891111111111111e-06,
      "loss": 0.4333,
      "step": 1900
    },
    {
      "epoch": 0.8567662565905096,
      "grad_norm": 4.734794616699219,
      "learning_rate": 6.780000000000001e-06,
      "loss": 0.4398,
      "step": 1950
    },
    {
      "epoch": 0.8787346221441125,
      "grad_norm": 6.354697227478027,
      "learning_rate": 6.668888888888889e-06,
      "loss": 0.4335,
      "step": 2000
    },
    {
      "epoch": 0.8787346221441125,
      "eval_runtime": 43.61,
      "eval_samples_per_second": 50.699,
      "eval_steps_per_second": 6.352,
      "step": 2000
    },
    {
      "epoch": 0.9007029876977153,
      "grad_norm": 5.872701644897461,
      "learning_rate": 6.557777777777778e-06,
      "loss": 0.4357,
      "step": 2050
    },
    {
      "epoch": 0.9226713532513181,
      "grad_norm": 6.833186626434326,
      "learning_rate": 6.446666666666668e-06,
      "loss": 0.428,
      "step": 2100
    },
    {
      "epoch": 0.9446397188049209,
      "grad_norm": 3.111837148666382,
      "learning_rate": 6.335555555555556e-06,
      "loss": 0.4238,
      "step": 2150
    },
    {
      "epoch": 0.9666080843585237,
      "grad_norm": 4.607555389404297,
      "learning_rate": 6.224444444444445e-06,
      "loss": 0.4312,
      "step": 2200
    },
    {
      "epoch": 0.9885764499121266,
      "grad_norm": 3.2802438735961914,
      "learning_rate": 6.113333333333333e-06,
      "loss": 0.4258,
      "step": 2250
    },
    {
      "epoch": 1.0105448154657293,
      "grad_norm": 3.9780943393707275,
      "learning_rate": 6.002222222222223e-06,
      "loss": 0.4367,
      "step": 2300
    },
    {
      "epoch": 1.0325131810193322,
      "grad_norm": 2.8939592838287354,
      "learning_rate": 5.891111111111112e-06,
      "loss": 0.4297,
      "step": 2350
    },
    {
      "epoch": 1.054481546572935,
      "grad_norm": 1.9969711303710938,
      "learning_rate": 5.78e-06,
      "loss": 0.4294,
      "step": 2400
    },
    {
      "epoch": 1.0764499121265378,
      "grad_norm": 5.172874927520752,
      "learning_rate": 5.6688888888888895e-06,
      "loss": 0.4446,
      "step": 2450
    },
    {
      "epoch": 1.0984182776801406,
      "grad_norm": 2.6499645709991455,
      "learning_rate": 5.557777777777778e-06,
      "loss": 0.4226,
      "step": 2500
    },
    {
      "epoch": 1.0984182776801406,
      "eval_runtime": 44.2655,
      "eval_samples_per_second": 49.949,
      "eval_steps_per_second": 6.258,
      "step": 2500
    },
    {
      "epoch": 1.1203866432337435,
      "grad_norm": 8.25985336303711,
      "learning_rate": 5.4466666666666665e-06,
      "loss": 0.4398,
      "step": 2550
    },
    {
      "epoch": 1.1423550087873462,
      "grad_norm": 3.1902101039886475,
      "learning_rate": 5.335555555555556e-06,
      "loss": 0.428,
      "step": 2600
    },
    {
      "epoch": 1.1643233743409491,
      "grad_norm": 2.481980800628662,
      "learning_rate": 5.224444444444445e-06,
      "loss": 0.4342,
      "step": 2650
    },
    {
      "epoch": 1.1862917398945518,
      "grad_norm": 3.995440721511841,
      "learning_rate": 5.113333333333333e-06,
      "loss": 0.4184,
      "step": 2700
    },
    {
      "epoch": 1.2082601054481548,
      "grad_norm": 2.2470922470092773,
      "learning_rate": 5.002222222222223e-06,
      "loss": 0.4248,
      "step": 2750
    },
    {
      "epoch": 1.2302284710017575,
      "grad_norm": 4.214659690856934,
      "learning_rate": 4.891111111111111e-06,
      "loss": 0.4205,
      "step": 2800
    },
    {
      "epoch": 1.2521968365553602,
      "grad_norm": 2.523831367492676,
      "learning_rate": 4.78e-06,
      "loss": 0.4369,
      "step": 2850
    },
    {
      "epoch": 1.2741652021089631,
      "grad_norm": 3.257397413253784,
      "learning_rate": 4.66888888888889e-06,
      "loss": 0.4218,
      "step": 2900
    },
    {
      "epoch": 1.2961335676625658,
      "grad_norm": 9.414968490600586,
      "learning_rate": 4.557777777777778e-06,
      "loss": 0.4358,
      "step": 2950
    },
    {
      "epoch": 1.3181019332161688,
      "grad_norm": 3.9936513900756836,
      "learning_rate": 4.446666666666667e-06,
      "loss": 0.4301,
      "step": 3000
    },
    {
      "epoch": 1.3181019332161688,
      "eval_runtime": 43.5855,
      "eval_samples_per_second": 50.728,
      "eval_steps_per_second": 6.355,
      "step": 3000
    },
    {
      "epoch": 1.3400702987697715,
      "grad_norm": 4.111684322357178,
      "learning_rate": 4.3355555555555565e-06,
      "loss": 0.4283,
      "step": 3050
    },
    {
      "epoch": 1.3620386643233744,
      "grad_norm": 2.988318920135498,
      "learning_rate": 4.2244444444444446e-06,
      "loss": 0.4255,
      "step": 3100
    },
    {
      "epoch": 1.384007029876977,
      "grad_norm": 4.057816028594971,
      "learning_rate": 4.1133333333333335e-06,
      "loss": 0.4187,
      "step": 3150
    },
    {
      "epoch": 1.40597539543058,
      "grad_norm": 2.9363341331481934,
      "learning_rate": 4.002222222222222e-06,
      "loss": 0.4253,
      "step": 3200
    },
    {
      "epoch": 1.4279437609841827,
      "grad_norm": 4.699889183044434,
      "learning_rate": 3.891111111111111e-06,
      "loss": 0.4297,
      "step": 3250
    },
    {
      "epoch": 1.4499121265377855,
      "grad_norm": 8.963944435119629,
      "learning_rate": 3.7800000000000002e-06,
      "loss": 0.4267,
      "step": 3300
    },
    {
      "epoch": 1.4718804920913884,
      "grad_norm": 5.565678119659424,
      "learning_rate": 3.668888888888889e-06,
      "loss": 0.4235,
      "step": 3350
    },
    {
      "epoch": 1.4938488576449913,
      "grad_norm": 2.3644628524780273,
      "learning_rate": 3.5577777777777785e-06,
      "loss": 0.421,
      "step": 3400
    },
    {
      "epoch": 1.515817223198594,
      "grad_norm": 3.171420097351074,
      "learning_rate": 3.446666666666667e-06,
      "loss": 0.4238,
      "step": 3450
    },
    {
      "epoch": 1.5377855887521967,
      "grad_norm": 2.5295143127441406,
      "learning_rate": 3.335555555555556e-06,
      "loss": 0.4206,
      "step": 3500
    },
    {
      "epoch": 1.5377855887521967,
      "eval_runtime": 43.6341,
      "eval_samples_per_second": 50.671,
      "eval_steps_per_second": 6.348,
      "step": 3500
    },
    {
      "epoch": 1.5597539543057997,
      "grad_norm": 3.1856725215911865,
      "learning_rate": 3.2244444444444444e-06,
      "loss": 0.4286,
      "step": 3550
    },
    {
      "epoch": 1.5817223198594026,
      "grad_norm": 2.755034923553467,
      "learning_rate": 3.1133333333333337e-06,
      "loss": 0.421,
      "step": 3600
    },
    {
      "epoch": 1.6036906854130053,
      "grad_norm": 3.8355822563171387,
      "learning_rate": 3.0022222222222227e-06,
      "loss": 0.4259,
      "step": 3650
    },
    {
      "epoch": 1.625659050966608,
      "grad_norm": 2.8305444717407227,
      "learning_rate": 2.891111111111111e-06,
      "loss": 0.425,
      "step": 3700
    },
    {
      "epoch": 1.647627416520211,
      "grad_norm": 4.72579288482666,
      "learning_rate": 2.7800000000000005e-06,
      "loss": 0.4262,
      "step": 3750
    },
    {
      "epoch": 1.6695957820738139,
      "grad_norm": 8.790594100952148,
      "learning_rate": 2.6688888888888894e-06,
      "loss": 0.4175,
      "step": 3800
    },
    {
      "epoch": 1.6915641476274166,
      "grad_norm": 2.92757248878479,
      "learning_rate": 2.557777777777778e-06,
      "loss": 0.4162,
      "step": 3850
    },
    {
      "epoch": 1.7135325131810193,
      "grad_norm": 5.188807487487793,
      "learning_rate": 2.446666666666667e-06,
      "loss": 0.4238,
      "step": 3900
    },
    {
      "epoch": 1.735500878734622,
      "grad_norm": 5.2501678466796875,
      "learning_rate": 2.3355555555555557e-06,
      "loss": 0.4157,
      "step": 3950
    },
    {
      "epoch": 1.757469244288225,
      "grad_norm": 7.545981407165527,
      "learning_rate": 2.2244444444444447e-06,
      "loss": 0.4177,
      "step": 4000
    },
    {
      "epoch": 1.757469244288225,
      "eval_runtime": 43.7223,
      "eval_samples_per_second": 50.569,
      "eval_steps_per_second": 6.335,
      "step": 4000
    },
    {
      "epoch": 1.7794376098418279,
      "grad_norm": 2.5410521030426025,
      "learning_rate": 2.1133333333333336e-06,
      "loss": 0.4212,
      "step": 4050
    },
    {
      "epoch": 1.8014059753954306,
      "grad_norm": 7.511455059051514,
      "learning_rate": 2.0022222222222225e-06,
      "loss": 0.4291,
      "step": 4100
    },
    {
      "epoch": 1.8233743409490333,
      "grad_norm": 3.854796886444092,
      "learning_rate": 1.8911111111111114e-06,
      "loss": 0.4282,
      "step": 4150
    },
    {
      "epoch": 1.8453427065026362,
      "grad_norm": 3.7559499740600586,
      "learning_rate": 1.7800000000000001e-06,
      "loss": 0.417,
      "step": 4200
    },
    {
      "epoch": 1.8673110720562391,
      "grad_norm": 3.1805367469787598,
      "learning_rate": 1.668888888888889e-06,
      "loss": 0.4308,
      "step": 4250
    },
    {
      "epoch": 1.8892794376098418,
      "grad_norm": 3.318599224090576,
      "learning_rate": 1.5577777777777777e-06,
      "loss": 0.42,
      "step": 4300
    },
    {
      "epoch": 1.9112478031634446,
      "grad_norm": 2.5674285888671875,
      "learning_rate": 1.4466666666666669e-06,
      "loss": 0.4173,
      "step": 4350
    },
    {
      "epoch": 1.9332161687170475,
      "grad_norm": 2.6895575523376465,
      "learning_rate": 1.3355555555555558e-06,
      "loss": 0.4167,
      "step": 4400
    },
    {
      "epoch": 1.9551845342706504,
      "grad_norm": 4.402460098266602,
      "learning_rate": 1.2244444444444445e-06,
      "loss": 0.428,
      "step": 4450
    },
    {
      "epoch": 1.9771528998242531,
      "grad_norm": 11.513273239135742,
      "learning_rate": 1.1133333333333334e-06,
      "loss": 0.4186,
      "step": 4500
    },
    {
      "epoch": 1.9771528998242531,
      "eval_runtime": 43.7388,
      "eval_samples_per_second": 50.55,
      "eval_steps_per_second": 6.333,
      "step": 4500
    },
    {
      "epoch": 1.9991212653778558,
      "grad_norm": 2.8942794799804688,
      "learning_rate": 1.0022222222222223e-06,
      "loss": 0.4191,
      "step": 4550
    },
    {
      "epoch": 2.0210896309314585,
      "grad_norm": 3.0550670623779297,
      "learning_rate": 8.911111111111112e-07,
      "loss": 0.418,
      "step": 4600
    },
    {
      "epoch": 2.0430579964850617,
      "grad_norm": 3.956533670425415,
      "learning_rate": 7.8e-07,
      "loss": 0.414,
      "step": 4650
    },
    {
      "epoch": 2.0650263620386644,
      "grad_norm": 3.3338377475738525,
      "learning_rate": 6.68888888888889e-07,
      "loss": 0.4154,
      "step": 4700
    },
    {
      "epoch": 2.086994727592267,
      "grad_norm": 3.5493757724761963,
      "learning_rate": 5.577777777777779e-07,
      "loss": 0.4222,
      "step": 4750
    },
    {
      "epoch": 2.10896309314587,
      "grad_norm": 3.335644006729126,
      "learning_rate": 4.466666666666667e-07,
      "loss": 0.4162,
      "step": 4800
    },
    {
      "epoch": 2.1309314586994725,
      "grad_norm": 6.152787685394287,
      "learning_rate": 3.3555555555555556e-07,
      "loss": 0.4124,
      "step": 4850
    },
    {
      "epoch": 2.1528998242530757,
      "grad_norm": 5.496007442474365,
      "learning_rate": 2.2444444444444445e-07,
      "loss": 0.4163,
      "step": 4900
    },
    {
      "epoch": 2.1748681898066784,
      "grad_norm": 2.0073726177215576,
      "learning_rate": 1.1333333333333336e-07,
      "loss": 0.4277,
      "step": 4950
    },
    {
      "epoch": 2.196836555360281,
      "grad_norm": 13.449897766113281,
      "learning_rate": 2.2222222222222225e-09,
      "loss": 0.4181,
      "step": 5000
    },
    {
      "epoch": 2.196836555360281,
      "eval_runtime": 43.7964,
      "eval_samples_per_second": 50.484,
      "eval_steps_per_second": 6.325,
      "step": 5000
    }
  ],
  "logging_steps": 50,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3032264297494080.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
